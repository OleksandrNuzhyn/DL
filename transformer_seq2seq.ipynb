{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Translation({\n",
       "     'en': Text(shape=(), dtype=string),\n",
       "     'pt': Text(shape=(), dtype=string),\n",
       " }),\n",
       " {'train': <SplitInfo num_examples=51785, num_shards=1>,\n",
       "  'validation': <SplitInfo num_examples=1193, num_shards=1>,\n",
       "  'test': <SplitInfo num_examples=1803, num_shards=1>})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.features, metadata.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, val_examples, test_examples = examples['train'], examples['validation'], examples[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade . \n",
      " and when you improve searchability , you actually take away the one advantage of print , which is serendipity . \n",
      "\n",
      "mas e se estes fatores fossem ativos ? \n",
      " but what if it were active ? \n",
      "\n",
      "mas eles não tinham a curiosidade de me testar . \n",
      " but they did n't test for curiosity . \n",
      "\n",
      "e esta rebeldia consciente é a razão pela qual eu , como agnóstica , posso ainda ter fé . \n",
      " and this conscious defiance is why i , as an agnostic , can still have faith . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(4).take(1):\n",
    "    for pt, en in zip(pt_examples.numpy(), en_examples.numpy()):\n",
    "        print(pt.decode(), \"\\n\", en.decode(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n",
      "\u001b[1m184801/184801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./ted_hrlr_translate_pt_en_converter_extracted'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.get_file(\n",
    "    'ted_hrlr_translate_pt_en_converter.zip',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/fs/ML/Ipynbs/DL/ted_hrlr_translate_pt_en_converter_extracted/ted_hrlr_translate_pt_en_converter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   72  117   79 1259 1491 2362   13   79  150  184  311   71  103\n",
      " 2308   74 2679   13  148   80   55 4840 1434 2423  540   15    3] \n",
      " and when you improve searchability , you actually take away the one advantage of print , which is serendipity . \n",
      "\n",
      "[   2   87   90  107   76  129 1852   30    3] \n",
      " but what if it were active ? \n",
      "\n",
      "[   2   87   83  149   50    9   56  664   85 2512   15    3] \n",
      " but they did n ' t test for curiosity . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, en_examples in train_examples.batch(3).take(1):\n",
    "    encoded = tokenizers.en.tokenize(en_examples)\n",
    "    decoded = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "    for enc, dec in zip(encoded.numpy(), decoded.numpy()):\n",
    "        print(enc, \"\\n\", dec.decode(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "    pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
    "    lengths.append(pt_tokens.row_lengths())\n",
    "\n",
    "    en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "    lengths.append(en_tokens.row_lengths())\n",
    "    print('.', end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Max tokens per example: {max_length}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 128\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch_optimized(pt, en):\n",
    "    @tf.function\n",
    "    def tokenize_and_process(pt, en):\n",
    "        pt = tokenizers.pt.tokenize(pt)\n",
    "        pt = pt[:, :MAX_TOKENS]\n",
    "        pt = pt.to_tensor()\n",
    "\n",
    "        en = tokenizers.en.tokenize(en)\n",
    "        en = en[:, :(MAX_TOKENS+1)]\n",
    "        \n",
    "        en_inputs = en[:, :-1].to_tensor() # Викидуємо [END] токен\n",
    "        en_labels = en[:, 1:].to_tensor() #  Викидуємо [START] токен\n",
    "        \n",
    "        return (pt, en_inputs), en_labels\n",
    "    \n",
    "    return tokenize_and_process(pt, en)\n",
    "\n",
    "def make_batches_optimized(dataset, shuffle_data=False):\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    options.experimental_optimization.map_parallelization = True\n",
    "    options.experimental_optimization.map_and_batch_fusion = True\n",
    "    options.experimental_optimization.noop_elimination = True\n",
    "    \n",
    "    if shuffle_data:\n",
    "        dataset = (\n",
    "            dataset\n",
    "            .shuffle(BUFFER_SIZE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .map(prepare_batch_optimized, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "            .with_options(options)\n",
    "        )\n",
    "    else:\n",
    "        dataset = (\n",
    "            dataset\n",
    "            .batch(BATCH_SIZE)\n",
    "            .map(prepare_batch_optimized, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "            .with_options(options)\n",
    "        )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches_optimized(train_examples, shuffle_data=True)\n",
    "val_batches = make_batches_optimized(val_examples, shuffle_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "batch_index = 0\n",
    "bugs_num = 0\n",
    "\n",
    "for batch in train_batches:\n",
    "    (pt, en_inputs), en_labels = batch\n",
    "\n",
    "    for idx in range(64):\n",
    "        if idx < len(pt):\n",
    "            pt_tokens = pt[idx].numpy()\n",
    "\n",
    "            if not any(token == 0 for token in pt_tokens) and pt_tokens[-1] != 3:\n",
    "                bugs_num += 1\n",
    "    \n",
    "    batch_index += 1\n",
    "\n",
    "print(bugs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=emb_dim, mask_zero=True) \n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=emb_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # Sets the relative scale\n",
    "        x *= tf.math.sqrt(tf.cast(self.emb_dim, tf.float32))\n",
    "        x += self.pos_encoding[tf.newaxis, :length, :]\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context)\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layer_norm(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "# x – це вхідні дані декодера (вектор query). Вони беруться з попереднього шару декодера.\n",
    "# context – це вихід із енкодера (вектори \"key\" та \"value\").\n",
    "\n",
    "# Енкодер: Він приймає вхідну послідовність (наприклад, запит користувача) та перетворює її у внутрішнє представлення. \n",
    "# Це представлення містить важливу інформацію про всі елементи вхідних даних. \n",
    "# Його передають як ключі (key) і значення (value), тому що вони слугують як база даних для пошуку релевантної інформації.\n",
    "\n",
    "# Декодер: Він формує запит (query) на основі свого поточного стану (наприклад, попередньо згенерованих слів) \n",
    "# використовує його для обчислення уваги по даних з енкодера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    \n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layer_norm(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask=True)\n",
    "    \n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layer_norm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, emb_dim, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(emb_dim),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq_model(x)])\n",
    "    x = self.layer_norm(x) \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, emb_dim, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=emb_dim,\n",
    "        dropout=dropout_rate)\n",
    "    self.ffn = FeedForward(emb_dim=emb_dim, dff=dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, emb_dim, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.emb_dim = emb_dim\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, emb_dim=emb_dim)\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(emb_dim=emb_dim,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.pos_embedding(x)  # (batch_size, seq_len, emb_dim)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    # Послідовно обробляємо дані, передаючи вихід одного шару на вхід наступного.\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, emb_dim, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=emb_dim,\n",
    "        dropout=dropout_rate)\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=emb_dim,\n",
    "        dropout=dropout_rate)\n",
    "    self.ffn = FeedForward(emb_dim=emb_dim, dff=dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x)\n",
    "    x = self.cross_attention(x, context)\n",
    "    x = self.ffn(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, emb_dim, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.emb_dim = emb_dim\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, emb_dim=emb_dim)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(emb_dim=emb_dim, \n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff, \n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.pos_embedding(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, emb_dim, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, emb_dim=emb_dim,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "    self.decoder = Decoder(num_layers=num_layers, emb_dim=emb_dim,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # context - вхідні речення португальською мовою (індекси токенів) - для енкодеру\n",
    "    # x - цільові речення англійською мовою (індекси токенів) - для декодеру\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, emb_dim)\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, emb_dim)\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    # Короткі речення з великою кількістю паддінгу отримують більший внесок від паддінгових позицій\n",
    "    # Тому видаляємо маску тільки з фінальних логітів, після того як усі обчислення уваги вже завершено\n",
    "    try:\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "emb_dim = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    emb_dim=emb_dim,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
    "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, emb_dim, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "    self.emb_dim = tf.cast(emb_dim, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.emb_dim) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(emb_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "\n",
    "  return tf.reduce_sum(match) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'transformer.weights.h5'\n",
    "\n",
    "class SaveEveryNSteps(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_freq=20, filepath=checkpoint_path):\n",
    "        super(SaveEveryNSteps, self).__init__()\n",
    "        self.save_freq = save_freq\n",
    "        self.filepath = filepath\n",
    "        self.steps = 0\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.steps += 1\n",
    "        if self.steps % self.save_freq == 0:\n",
    "            self.model.save_weights(self.filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveEveryNSteps(save_freq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.fit(train_batches, epochs=1, validation_data=val_batches, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.build([(None, None), (None, None)])  # (batch_size, sequence_length) для обох входів\n",
    "transformer.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      predictions = predictions[:, -1:, :]\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      output_array = output_array.write(i + 1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    text = tokenizers.en.detokenize(output)[0]\n",
    "\n",
    "    tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "\n",
    "    return text, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(tokenizers, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : este é um problema que temos que resolver.\n",
      "Prediction     : simulationade sensitive light elephant elephant visitors visitors visitors substance diameter go gulf happen disappeared collaborators implications majoritywing light thus novel clever facilities thus novel manipulate investigation broke ceiling likely likely likelyvation tumor transactions clock engaging account addingunk years closer closer closer affects cause lightrap shares plainunkunkunkunkunkugh steel independence wealthyugh engagement profileborn featureunk relate spaces vocalrable smarter was was goes reserve responds spaces pathway angles smarteraid primates flexible obama flexible you taking primates primates primates orbit orbit orbit primates primates primates primatespressed orbit orbit sexting pizza super lettingnana cold orbit chemical orbitv choosingoe are cute cute cute cute abstractographicoeographic cute cute outside egyptians regimewing\n",
      "Ground truth   : this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "sentence = 'este é um problema que temos que resolver.'\n",
    "ground_truth = 'this is a problem we have to solve .'\n",
    "\n",
    "translated_text, translated_tokens = translator(tf.constant(sentence))\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
