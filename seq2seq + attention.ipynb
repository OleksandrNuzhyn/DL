{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import subprocess\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUMemoryManager:\n",
    "    def __init__(self, memory_fraction=0.5, allow_growth=True):\n",
    "        self.memory_fraction = memory_fraction\n",
    "        self.allow_growth = allow_growth\n",
    "        self.gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        \n",
    "    def get_total_gpu_memory(self):\n",
    "        try:\n",
    "            output = subprocess.check_output(\n",
    "                ['nvidia-smi', '--query-gpu=memory.total', '--format=csv,nounits,noheader'],\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "            return int(output.strip())\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def configure(self):\n",
    "        if not self.gpus:\n",
    "            print(\"GPU не знайдено\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            total_memory = self.get_total_gpu_memory()\n",
    "            if total_memory is None:\n",
    "                print(\"Не вдалося отримати інформацію про пам'ять GPU\")\n",
    "                return False\n",
    "\n",
    "            memory_limit = int(total_memory * self.memory_fraction)\n",
    "\n",
    "            for gpu in self.gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, self.allow_growth)\n",
    "                \n",
    "                tf.config.experimental.set_virtual_device_configuration(\n",
    "                    gpu,\n",
    "                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]\n",
    "                )\n",
    "            \n",
    "            print(f\"GPU налаштовано: ліміт {memory_limit}MB ({self.memory_fraction*100}%)\")\n",
    "            return True\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Помилка конфігурації GPU: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU налаштовано: ліміт 4096MB (50.0%)\n"
     ]
    }
   ],
   "source": [
    "gpu_manager = GPUMemoryManager(memory_fraction=0.5, allow_growth=True)\n",
    "if not gpu_manager.configure():\n",
    "    print(\"Помилка налаштування GPU. Вихід\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainingMonitor:\n",
    "    def __init__(self, log_frequency=10):\n",
    "        self.log_frequency = log_frequency\n",
    "        self.peak_memory = 0\n",
    "        self.start_time = None\n",
    "        self.current_epoch = 0\n",
    "        self.current_batch = 0\n",
    "\n",
    "    def get_detailed_memory_info(self):\n",
    "        memory = tf.config.experimental.get_memory_info('GPU:0')\n",
    "        return {\n",
    "            'tf_current': memory['current'] / (1024 * 1024),\n",
    "            'tf_peak': memory['peak'] / (1024 * 1024)\n",
    "        }\n",
    "\n",
    "    def print_memory_stats(self):\n",
    "        memory = self.get_detailed_memory_info()\n",
    "        if memory:\n",
    "            print(f\"TensorFlow reported memory: {memory['tf_current']:.0f}MB (Peak: {memory['tf_peak']:.0f}MB)\")\n",
    "            self.peak_memory = max(self.peak_memory, memory['tf_current'])\n",
    "            \n",
    "    def on_training_start(self):\n",
    "        self.start_time = datetime.now()\n",
    "        print(\"Running training...\")\n",
    "        \n",
    "    def on_epoch_start(self):\n",
    "        self.current_epoch += 1\n",
    "        self.current_batch = 0\n",
    "        print(f\"\\nEpoch {self.current_epoch}\")\n",
    "        \n",
    "        print(\"Epoch start: \", end=\"\")\n",
    "        self.print_memory_stats()\n",
    "        \n",
    "    def on_batch_end(self, loss, accuracy):\n",
    "        self.current_batch += 1\n",
    "        if self.current_batch % self.log_frequency == 0:\n",
    "            print(f\"Batch {self.current_batch} - Loss: {loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "            self.print_memory_stats()\n",
    "\n",
    "    def on_epoch_end(self, train_loss, train_accuracy, valid_loss, valid_accuracy):\n",
    "        print(f\"\\nTrain Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Valid Loss: {valid_loss:.4f} - Valid Accuracy: {valid_accuracy:.4f}\")\n",
    "        print(\"Epoch end: \", end=\"\")\n",
    "        self.print_memory_stats()\n",
    "\n",
    "    def on_training_end(self):\n",
    "        duration = datetime.now() - self.start_time\n",
    "        print(\"\\nEnd of training...\")\n",
    "        print(f\"Total duration: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!', ',', 'submissively']\n",
      "[True, True, False, False, True, True, False, False, False, False]\n",
      "['Zwei', 'junge', 'weiße', 'Männer', 'sind', 'im', 'Freien', 'in', 'der', 'Nähe', 'vieler', 'Büsche', '.']\n",
      "[True, False, False, False, True, True, False, True, True, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "string = \"What a lovely day it is today!, submissively\"\n",
    "print([token.text for token in en_nlp.tokenizer(string)])\n",
    "print([token.is_stop for token in en_nlp.tokenizer(string)])\n",
    "\n",
    "string = 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'\n",
    "print([token.text for token in de_nlp.tokenizer(string)])\n",
    "print([token.is_stop for token in de_nlp.tokenizer(string)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: train_data[0][key] for key in [\"en_tokens\", \"de_tokens\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [unk_token, pad_token, sos_token, eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.models import WordLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokenized_sentences, min_freq, special_tokens):\n",
    "    vocab = {token: idx for idx, token in enumerate(special_tokens)}\n",
    "\n",
    "    filtered_sentences = [\n",
    "        [word for word in sentence if word not in [\"<sos>\", \"<eos>\"]]\n",
    "        for sentence in tokenized_sentences\n",
    "    ]\n",
    "\n",
    "    word_counts = Counter(word for sentence in filtered_sentences for word in sentence)\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = build_vocab(train_data[\"en_tokens\"], min_freq, special_tokens)\n",
    "de_vocab = build_vocab(train_data[\"de_tokens\"], min_freq, special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5893, 7853)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(de_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<unk>', '<pad>', '<sos>', '<eos>', 'two', 'young'],\n",
       " ['<unk>', '<pad>', '<sos>', '<eos>', 'zwei', 'junge'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word, _ in en_vocab.items()][:6], [word for word, _ in de_vocab.items()][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = Tokenizer(WordLevel(en_vocab, unk_token=unk_token))\n",
    "de_tokenizer = Tokenizer(WordLevel(de_vocab, unk_token=unk_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer використовується для перетворення вже готових токенів в числа зі словника і навпаки. Якщо такого токену немає в словнику, Tokenizer автоматично замінює його на токен <\"unk\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[], normalizer=None, pre_tokenizer=None, post_processor=None, decoder=None, model=WordLevel(vocab={\"<unk>\":0, \"<pad>\":1, \"<sos>\":2, \"<eos>\":3, \"two\":4, \"young\":5, \",\":6, \"white\":7, \"males\":8, \"are\":9, \"outside\":10, \"near\":11, \"many\":12, \"bushes\":13, \".\":14, \"several\":15, \"men\":16, \"in\":17, \"hard\":18, \"hats\":19, \"operating\":20, \"a\":21, \"giant\":22, \"pulley\":23, \"system\":24, \"little\":25, \"girl\":26, \"climbing\":27, \"into\":28, \"wooden\":29, \"playhouse\":30, \"man\":31, \"blue\":32, \"shirt\":33, \"is\":34, \"standing\":35, \"on\":36, \"ladder\":37, \"cleaning\":38, \"window\":39, \"at\":40, \"the\":41, \"stove\":42, \"preparing\":43, \"food\":44, \"green\":45, \"holds\":46, \"guitar\":47, \"while\":48, \"other\":49, \"observes\":50, \"his\":51, \"smiling\":52, \"stuffed\":53, \"lion\":54, \"trendy\":55, \"talking\":56, \"her\":57, \"cellphone\":58, \"gliding\":59, \"slowly\":60, \"down\":61, \"street\":62, \"woman\":63, \"with\":64, \"large\":65, \"purse\":66, \"walking\":67, \"by\":68, \"gate\":69, \"boys\":70, \"dancing\":71, \"poles\":72, \"middle\":73, \"of\":74, \"night\":75, \"ballet\":76, \"class\":77, \"five\":78, \"girls\":79, \"jumping\":80, \"sequence\":81, \"four\":82, \"guys\":83, \"three\":84, \"wearing\":85, \"one\":86, \"not\":87, \"top\":88, \"staircase\":89, \"black\":90, \"dog\":91, \"and\":92, \"spotted\":93, \"fighting\":94, \"neon\":95, \"orange\":96, \"uniform\":97, \"driving\":98, ...}, unk_token=\"<unk>\")),\n",
       " Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[], normalizer=None, pre_tokenizer=None, post_processor=None, decoder=None, model=WordLevel(vocab={\"<unk>\":0, \"<pad>\":1, \"<sos>\":2, \"<eos>\":3, \"zwei\":4, \"junge\":5, \"weiße\":6, \"männer\":7, \"sind\":8, \"im\":9, \"freien\":10, \"in\":11, \"der\":12, \"nähe\":13, \"vieler\":14, \"büsche\":15, \".\":16, \"mehrere\":17, \"mit\":18, \"schutzhelmen\":19, \"bedienen\":20, \"ein\":21, \"kleines\":22, \"mädchen\":23, \"klettert\":24, \"spielhaus\":25, \"aus\":26, \"holz\":27, \"mann\":28, \"einem\":29, \"blauen\":30, \"hemd\":31, \"steht\":32, \"auf\":33, \"einer\":34, \"leiter\":35, \"und\":36, \"putzt\":37, \"fenster\":38, \"stehen\":39, \"am\":40, \"herd\":41, \"bereiten\":42, \"essen\":43, \"zu\":44, \"grün\":45, \"hält\":46, \"eine\":47, \"gitarre\":48, \",\":49, \"während\":50, \"andere\":51, \"sein\":52, \"ansieht\":53, \"lächelt\":54, \"einen\":55, \"ausgestopften\":56, \"löwen\":57, \"an\":58, \"schickes\":59, \"spricht\":60, \"dem\":61, \"handy\":62, \"sie\":63, \"langsam\":64, \"die\":65, \"straße\":66, \"frau\":67, \"großen\":68, \"geldbörse\":69, \"geht\":70, \"tor\":71, \"vorbei\":72, \"jungen\":73, \"tanzen\":74, \"mitten\":75, \"nacht\":76, \"pfosten\":77, \"ballettklasse\":78, \"fünf\":79, \"nacheinander\":80, \"springen\":81, \"vier\":82, \"typen\":83, \"von\":84, \"denen\":85, \"drei\":86, \"hüte\":87, \"tragen\":88, \"nicht\":89, \"oben\":90, \"treppenhaus\":91, \"schwarzer\":92, \"hund\":93, \"gefleckter\":94, \"kämpfen\":95, \"neongrünen\":96, \"orangefarbenen\":97, \"uniform\":98, ...}, unk_token=\"<unk>\")))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer, de_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[21]\n",
      "[243]\n",
      "[74]\n",
      "[16]\n",
      "[9]\n",
      "[1045]\n",
      "[1249]\n",
      "[1504]\n",
      "[21]\n",
      "[671]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "for word in valid_data[\"en_tokens\"][0]:\n",
    "    print(en_tokenizer.encode(word).ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_tokenizer, de_tokenizer):\n",
    "    en_ids = [en_tokenizer.token_to_id(token) or en_tokenizer.token_to_id(\"<unk>\") for token in example[\"en_tokens\"]]\n",
    "    de_ids = [de_tokenizer.token_to_id(token) or de_tokenizer.token_to_id(\"<unk>\") for token in example[\"de_tokens\"]]\n",
    "\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc425cafa5c4f56b4d4c8af9a308eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c252dd20ecaa4c189282b7fb7a05dfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3744f717534e099e8a22f38ca30b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"en_tokenizer\": en_tokenizer, \"de_tokenizer\": de_tokenizer}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 3],\n",
       " [('<unk>', 0),\n",
       "  ('<pad>', 1),\n",
       "  ('<sos>', 2),\n",
       "  ('<eos>', 3),\n",
       "  ('two', 4),\n",
       "  ('young', 5),\n",
       "  (',', 6),\n",
       "  ('white', 7),\n",
       "  ('males', 8),\n",
       "  ('are', 9),\n",
       "  ('outside', 10),\n",
       "  ('near', 11),\n",
       "  ('many', 12),\n",
       "  ('bushes', 13),\n",
       "  ('.', 14)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"en_tokens\"][0], train_data[\"en_ids\"][0], [(word, value) for _, (word, value) in enumerate(en_vocab.items())][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(data, batch_size, pad_index, shuffle=False):\n",
    "    max_length = max(\n",
    "        max(len(seq) for seq in data[\"en_ids\"]),\n",
    "        max(len(seq) for seq in data[\"de_ids\"])\n",
    "    )\n",
    "    \n",
    "    en_padded = tf.constant(tf.keras.utils.pad_sequences(\n",
    "        data[\"en_ids\"], \n",
    "        padding='post',\n",
    "        maxlen=max_length,\n",
    "        value=pad_index\n",
    "    ))\n",
    "\n",
    "    de_padded = tf.constant(tf.keras.utils.pad_sequences(\n",
    "        data[\"de_ids\"],\n",
    "        padding='post',\n",
    "        maxlen=max_length,\n",
    "        value=pad_index\n",
    "    ))\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices({\n",
    "        \"en_ids\": en_padded,\n",
    "        \"de_ids\": de_padded\n",
    "    })\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(data))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder=True відкидає неповний останній батч\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE) # Використання prefetch для завантаження нового batch під час обробки поточного\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "pad_index = en_vocab[\"<pad>\"]\n",
    "\n",
    "train_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the train dataset: 226\n",
      "en_ids shape: (128, 46)\n",
      "de_ids shape: (128, 46)\n"
     ]
    }
   ],
   "source": [
    "num_batches = 0\n",
    "for batch in train_loader:\n",
    "    num_batches += 1\n",
    "\n",
    "print(f\"Number of batches in the train dataset: {num_batches}\")\n",
    "\n",
    "for batch in train_loader.take(1):\n",
    "    print(\"en_ids shape:\", batch[\"en_ids\"].shape)\n",
    "    print(\"de_ids shape:\", batch[\"de_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout):\n",
    "        super(Encoder, self).__init__() # Щоб отримати доступ до батьківських методів (клас Model)\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=embedding_dim)\n",
    "        self.gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=encoder_hidden_dim, return_sequences=True))\n",
    "        self.dense = tf.keras.layers.Dense(decoder_hidden_dim, activation=\"tanh\")\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        encoder_all_states = self.gru(embedded)\n",
    "        # encoder_all_states = [batch size, src length, encoder_hidden_dim * 2] - стани для всіх токенів в Bidirectional\n",
    "\n",
    "        encoder_last_state = encoder_all_states[:, -1, :]\n",
    "        # encoder_last_state = [batch_size, encoder_hidden_dim * 2]\n",
    "\n",
    "        encoder_last_state = self.dense(encoder_last_state)\n",
    "        # encoder_last_state = [batch size, decoder_hidden_dim]\n",
    "\n",
    "        return encoder_all_states, encoder_last_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найкращий механізм уваги для GRU seq2seq - Bahdanau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, decoder_hidden_dim):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        # Обираємо розмірність (decoder_hidden_dim), бо:\n",
    "        # 1) Ми хочемо, щоб вектори від енкодера і декодера були в одному векторному просторі для обчислення уваги\n",
    "        # 2) decoder_hidden_dim зазвичай менше, ніж encoder_hidden_dim * 2 (зменшує кількість параметрів)\n",
    "\n",
    "        self.W1 = tf.keras.layers.Dense(decoder_hidden_dim)\n",
    "        self.W2 = tf.keras.layers.Dense(decoder_hidden_dim)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, decoder_hidden_state, encoder_all_states):\n",
    "        # decoder_hidden_state = [batch size, decoder_hidden_dim]\n",
    "\n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        # decoder_hidden_state = [batch_size, 1, decoder_hidden_dim]\n",
    "        \n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_all_states) + self.W2(decoder_hidden_state)))\n",
    "        # Dense layer застосовується лише до останньої осі\n",
    "        # self.W1(encoder_all_states) = [batch_size, src_length, decoder_hidden_dim]\n",
    "        # self.W2(decoder_hidden_state) = [batch_size, 1, decoder_hidden_dim]\n",
    "        # При додаванні матриць використовується broadcasting для W2 матриці по осі 1\n",
    "        # score = [batch size, src_length, 1]\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # Визначення впливу вагів всіх станів на контекстний вектор\n",
    "        # attention_weights = [batch size, src_length, 1]\n",
    "\n",
    "        context_vector = attention_weights * encoder_all_states\n",
    "        # context_vector = [batch size, src_length, encoder_hidden_dim * 2]\n",
    "        \n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        # Обчислюємо зважену суму всіх станів\n",
    "        # context_vector = [batch size, encoder_hidden_dim * 2]\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, output_dim, embedding_dim, decoder_hidden_dim, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=output_dim, output_dim=embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(units=decoder_hidden_dim, return_sequences=True)\n",
    "        self.attention = BahdanauAttention(decoder_hidden_dim)\n",
    "        self.dense = tf.keras.layers.Dense(output_dim, activation=\"softmax\")\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, input_token, decoder_last_state, encoder_all_states):\n",
    "        # Перетворює індекс вхідного токена у вектор\n",
    "        embedded = self.dropout(self.embedding(input_token))\n",
    "        # embedded = [batch_size, 1, embedding_dim]\n",
    "\n",
    "        context_vector = self.attention(decoder_last_state, encoder_all_states)\n",
    "        # context_vector = [batch_size, encoder_hidden_dim * 2]\n",
    "\n",
    "        context_vector = tf.expand_dims(context_vector, 1)\n",
    "        # context_vector = [batch_size, 1, encoder_hidden_dim * 2]\n",
    "\n",
    "        gru_input = tf.concat([embedded, context_vector], axis=-1)\n",
    "        # gru_input = [batch_size, 1, embedding_dim + encoder_hidden_dim * 2]\n",
    "\n",
    "        decoder_all_states = self.gru(gru_input, initial_state=decoder_last_state)\n",
    "        # GRU отримує свій попередній прихований стан, і gru_input (контекстний вектор і новий вхідний токен), і на їх основі обчислює новий прихований стан\n",
    "        # decoder_all_states = [batch_size, 1, decoder_hidden_dim]\n",
    "\n",
    "        decoder_new_state = decoder_all_states[:, -1, :]\n",
    "        # decoder_new_state: [batch_size, decoder_hidden_dim]\n",
    "\n",
    "        output = self.dense(decoder_all_states)\n",
    "        # output = [batch_size, 1, output_dim] (output_dim - розмірність словника) \n",
    "\n",
    "        return output, decoder_new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    # На вхід подається два пакета (X batch, y batch)\n",
    "    def call(self, src, trg, teacher_forcing_ratio):\n",
    "        # src: Вхідна послідовність (англійський текст) [batch_size, src_len]\n",
    "        # trg: Вихідна послідовність (німецький текст) [batch_size, trg_len]\n",
    "\n",
    "        batch_size = tf.shape(src)[0]\n",
    "        trg_len = tf.shape(trg)[1]\n",
    "        output_dim = self.decoder.output_dim\n",
    "        \n",
    "        # outputs - тензор для зберігання результатів (ймовірності для слів на кожному кроці для одного batch)\n",
    "        outputs = tf.zeros([batch_size, trg_len, output_dim])\n",
    "\n",
    "        encoder_all_states, encoder_last_state = self.encoder(src)\n",
    "\n",
    "        # Першим станом декодеру є останній стан енкодеру\n",
    "        decoder_current_hidden_state = encoder_last_state\n",
    "\n",
    "        # Обираємо початковий decoder_input для кожного елементу y пакеті (<sos>)\n",
    "        decoder_input = tf.expand_dims(trg[:, 0], 1)\n",
    "        # decoder_input = [batch_size, 1]\n",
    "\n",
    "        for t in tf.range(1, trg_len):\n",
    "            step_output, decoder_current_hidden_state = self.decoder(decoder_input, decoder_current_hidden_state, encoder_all_states)\n",
    "            # step_output - [batch_size, 1, output_dim] (зберігає ймовірності для слів на кроці t)\n",
    "\n",
    "            outputs = tf.tensor_scatter_nd_update(\n",
    "                outputs,\n",
    "                tf.stack([tf.range(batch_size), tf.fill([batch_size], t)], axis=1),\n",
    "                tf.squeeze(step_output, axis=1)\n",
    "            )\n",
    "            # outputs - тензор, який буде оновлюватися\n",
    "            # tf.range(batch_size): Генерує тензор розміру [batch_size], де кожен елемент — це індекс від 0 до batch_size-1. (буде представляти індекси рядків для кожного елемента в пакеті)\n",
    "            # tf.fill([batch_size], t) - Створює тензор розміру [batch_size], де всі елементи рівні значенню t (буде представляти індекси стовпців)\n",
    "            # tf.stack(..., axis=1): Об'єднує ці два тензори вздовж нової осі (вісь 1)\n",
    "            # tf.squeeze(step_output, axis=1) - видаляє другу вісь (вісь 1)\n",
    "\n",
    "            teacher_force = tf.random.uniform([]) < teacher_forcing_ratio\n",
    "            pred_tokens = tf.cast(tf.argmax(step_output, axis=-1), tf.int32)\n",
    "            # pred_tokens = [batch_size, 1]\n",
    "\n",
    "            trg_tokens = tf.cast(tf.expand_dims(trg[:, t], 1), tf.int32)\n",
    "            # trg_tokens = [batch_size, 1]\n",
    "\n",
    "            decoder_input = tf.where(teacher_force, trg_tokens, pred_tokens)\n",
    "            # Якщо teacher_force = True, то decoder_input = trg_tokens, інакше decoder_input = pred_tokens\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target: [<sos> word1 word2 <eos> <pad>] - прибираємо перший токен для обрахунку loss\n",
    "# output: [word1 word2 <eos> <pad> <pad>] - прибираємо останній токен для правильного обрахунку loss\n",
    "# target_new: [word1 word2 <eos> <pad>]\n",
    "# output_new: [word1 word2 <eos> <pad>]\n",
    "# <pad> при обрахунку loss не враховується (masking)\n",
    "\n",
    "# Функція для тренування 1 batch\n",
    "# Градієнт (∂loss/∂w) показує, як зміниться loss при зміні ваги w. Це означає, що під час тренування важливо тільки те, як ми обчислюємо loss\n",
    "def train_step(model, src, trg, optimizer, loss_fn, teacher_forcing_ratio):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Передбачення моделі для одного batch\n",
    "        output = model(src, trg, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "        # output = [batch_size, trg_len, output_dim]\n",
    "        # trg = [batch_size, trg_len]\n",
    "        \n",
    "        # Підготовка даних для обчислення loss\n",
    "        output = output[:, :-1]\n",
    "        target = trg[:, 1:]\n",
    "        \n",
    "        # Змінюємо форму для обчислення loss\n",
    "        output_flat = tf.reshape(output, [-1, output.shape[-1]])\n",
    "        # output_flat = [всі_токени_в_пакеті, output_dim]\n",
    "        target_flat = tf.reshape(target, [-1])\n",
    "        # target_flat = [всі_токени_в_пакеті]\n",
    "\n",
    "        losses = loss_fn(target_flat, output_flat)\n",
    "        loss = tf.reduce_sum(losses)\n",
    "\n",
    "    # Обчислюємо градієнти від функції втрат loss щодо всіх тренованих параметрів моделі\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Функція tf.clip_by_global_norm використовується для запобігання вибуху градієнтів\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, clip_norm=1.0)\n",
    "\n",
    "    # Оптимізатор оновлює параметри моделі, використовуючи обчислені градієнти\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # zip(gradients, model.trainable_variables) створює пари (градієнт, вага), і оптимізатор застосовує їх для коригування ваг моделі\n",
    "\n",
    "    # Обчислюємо точність\n",
    "    predictions = tf.cast(tf.argmax(output_flat, axis=1), tf.int32)\n",
    "    target_flat = tf.cast(target_flat, tf.int32)\n",
    "\n",
    "    # Створюємо маску для ігнорування padding токенів\n",
    "    # target_flat = [5, 8, 1, 1, 3, 1] (1 - pad token)\n",
    "    # mask буде = [True, True, False, False, True, False]\n",
    "    # boolean_mask залишає тільки ті елементи, де маска має значення True\n",
    "    \n",
    "    mask = tf.math.not_equal(target_flat, en_vocab[\"<pad>\"])\n",
    "\n",
    "    masked_predictions = tf.boolean_mask(predictions, mask)\n",
    "    masked_targets = tf.boolean_mask(target_flat, mask)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(masked_predictions, masked_targets), tf.float32))\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_loader, loss_fn):\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in valid_loader:\n",
    "        src, trg = batch[\"en_ids\"], batch[\"de_ids\"]\n",
    "        \n",
    "        # Передбачення моделі (без teacher forcing)\n",
    "        output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "        \n",
    "        # Підготовка даних для обчислення loss\n",
    "        output = output[:, :-1]\n",
    "        target = trg[:, 1:]\n",
    "        \n",
    "        output_flat = tf.reshape(output, [-1, output.shape[-1]])\n",
    "        target_flat = tf.reshape(target, [-1])\n",
    "        \n",
    "        losses = loss_fn(target_flat, output_flat)\n",
    "        loss = tf.reduce_sum(losses)\n",
    "        \n",
    "        # Обчислюємо точність\n",
    "        predictions = tf.cast(tf.argmax(output_flat, axis=1), tf.int32)\n",
    "        target_flat = tf.cast(target_flat, tf.int32)\n",
    "        \n",
    "        mask = tf.math.not_equal(target_flat, en_vocab[\"<pad>\"])\n",
    "        masked_predictions = tf.boolean_mask(predictions, mask)\n",
    "        masked_targets = tf.boolean_mask(target_flat, mask)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(masked_predictions, masked_targets), tf.float32))\n",
    "        \n",
    "        total_loss += loss\n",
    "        total_accuracy += accuracy\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    \n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Під час тренування:\n",
    "train_loss - обчислюється лише на поточному batch;\n",
    "valid_loss - обчислюється на всій валідаційній вибірці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, optimizer, loss_fn, epochs, teacher_forcing_ratio):\n",
    "    model.trainable = True\n",
    "    monitor = CustomTrainingMonitor(log_frequency=10)\n",
    "    monitor.on_training_start()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    checkpoint_path = \"checkpoints/best_seq2seq_attn_model_weights.weights.h5\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        monitor.on_epoch_start()\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_train_accuracy = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            src, trg = batch[\"en_ids\"], batch[\"de_ids\"]\n",
    "            \n",
    "            batch_loss, batch_accuracy = train_step(model, src, trg, optimizer, loss_fn, teacher_forcing_ratio)\n",
    "\n",
    "            total_train_loss += batch_loss\n",
    "            total_train_accuracy += batch_accuracy\n",
    "                \n",
    "            monitor.on_batch_end(batch_loss, batch_accuracy)\n",
    "        \n",
    "        num_batches = batch_idx + 1\n",
    "        avg_train_loss = total_train_loss / num_batches\n",
    "        avg_train_accuracy = total_train_accuracy / num_batches\n",
    "    \n",
    "        avg_val_loss, avg_val_accuracy = evaluate(model, valid_loader, loss_fn)\n",
    "\n",
    "        monitor.on_epoch_end(\n",
    "            avg_train_loss, \n",
    "            avg_train_accuracy,\n",
    "            avg_val_loss,\n",
    "            avg_val_accuracy\n",
    "        )\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            model.save_weights(checkpoint_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                print(f\"\\nEarly stopping on epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    model.load_weights(checkpoint_path)\n",
    "    model.save('seq2seq_attn_model.keras')\n",
    "    monitor.on_training_end()\n",
    "\n",
    "    trainable_params = sum(tf.size(v) for v in model.trainable_variables)\n",
    "    non_trainable_params = sum(tf.size(v) for v in model.non_trainable_variables)\n",
    "    total_params = trainable_params + non_trainable_params\n",
    "\n",
    "    print(\"\\nModel Parameters Summary:\")\n",
    "    print(f\"Trainable params: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable params: {non_trainable_params:,}\")\n",
    "    print(f\"Total params: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    encoder = Encoder(input_dim=len(en_vocab), \n",
    "                     embedding_dim=128,\n",
    "                     encoder_hidden_dim=128,\n",
    "                     decoder_hidden_dim=128,\n",
    "                     dropout=0.2)\n",
    "    decoder = Decoder(output_dim=len(de_vocab), \n",
    "                     embedding_dim=128, \n",
    "                     decoder_hidden_dim=128, \n",
    "                     dropout=0.2)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    return Seq2Seq(encoder, decoder), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE, ignore_class=en_vocab[\"<pad>\"])\n",
    "epochs = 3\n",
    "teacher_forcing_ratio=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training...\n",
      "\n",
      "Epoch 1\n",
      "Epoch start: TensorFlow reported memory: 410MB (Peak: 3585MB)\n",
      "Batch 10 - Loss: 13216.4678 - Accuracy: 0.0762\n",
      "TensorFlow reported memory: 461MB (Peak: 3585MB)\n",
      "Batch 20 - Loss: 11538.7812 - Accuracy: 0.0747\n",
      "TensorFlow reported memory: 461MB (Peak: 3585MB)\n",
      "Batch 30 - Loss: 10453.6914 - Accuracy: 0.0743\n",
      "TensorFlow reported memory: 461MB (Peak: 3585MB)\n",
      "Batch 40 - Loss: 10284.2500 - Accuracy: 0.0739\n",
      "TensorFlow reported memory: 461MB (Peak: 3585MB)\n",
      "Batch 50 - Loss: 10028.8594 - Accuracy: 0.0750\n",
      "TensorFlow reported memory: 461MB (Peak: 3585MB)\n",
      "Batch 60 - Loss: 10031.8359 - Accuracy: 0.0788\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 70 - Loss: 10475.5762 - Accuracy: 0.0856\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 80 - Loss: 10409.7383 - Accuracy: 0.0944\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 90 - Loss: 9933.1768 - Accuracy: 0.1093\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 100 - Loss: 9769.0898 - Accuracy: 0.0981\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 110 - Loss: 10641.0586 - Accuracy: 0.1007\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 120 - Loss: 9851.5186 - Accuracy: 0.1265\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 130 - Loss: 10011.9375 - Accuracy: 0.1203\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 140 - Loss: 10155.4766 - Accuracy: 0.1285\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 150 - Loss: 10325.1807 - Accuracy: 0.1247\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 160 - Loss: 10078.0977 - Accuracy: 0.1346\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 170 - Loss: 9788.6152 - Accuracy: 0.1343\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 180 - Loss: 9410.3320 - Accuracy: 0.1423\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 190 - Loss: 9206.0264 - Accuracy: 0.1467\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 200 - Loss: 10389.3301 - Accuracy: 0.1129\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 210 - Loss: 9367.1758 - Accuracy: 0.1373\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 220 - Loss: 9452.0244 - Accuracy: 0.1380\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "\n",
      "Train Loss: 10199.0010 - Train Accuracy: 0.1084\n",
      "Valid Loss: 9480.4893 - Valid Accuracy: 0.1359\n",
      "Epoch end: TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "\n",
      "Epoch 2\n",
      "Epoch start: TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 10 - Loss: 9761.3535 - Accuracy: 0.1290\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 20 - Loss: 9528.9219 - Accuracy: 0.1519\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 30 - Loss: 9315.4082 - Accuracy: 0.1340\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 40 - Loss: 9487.0908 - Accuracy: 0.1188\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 50 - Loss: 9280.6396 - Accuracy: 0.1446\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 60 - Loss: 9543.1387 - Accuracy: 0.1449\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 70 - Loss: 9682.1680 - Accuracy: 0.1366\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 80 - Loss: 9164.1191 - Accuracy: 0.1559\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 90 - Loss: 9930.0586 - Accuracy: 0.1379\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 100 - Loss: 9626.5879 - Accuracy: 0.1392\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 110 - Loss: 9198.4941 - Accuracy: 0.1454\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 120 - Loss: 9415.4082 - Accuracy: 0.1403\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 130 - Loss: 9188.8047 - Accuracy: 0.1437\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 140 - Loss: 8926.3145 - Accuracy: 0.1385\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 150 - Loss: 9486.4854 - Accuracy: 0.1342\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 160 - Loss: 9684.1641 - Accuracy: 0.1394\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 170 - Loss: 9606.1455 - Accuracy: 0.1476\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 180 - Loss: 9120.7061 - Accuracy: 0.1454\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 190 - Loss: 9499.1025 - Accuracy: 0.1386\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 200 - Loss: 8912.7930 - Accuracy: 0.1574\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 210 - Loss: 9028.8604 - Accuracy: 0.1609\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 220 - Loss: 9558.9482 - Accuracy: 0.1532\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "\n",
      "Train Loss: 9457.0146 - Train Accuracy: 0.1422\n",
      "Valid Loss: 9377.7451 - Valid Accuracy: 0.1392\n",
      "Epoch end: TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "\n",
      "Epoch 3\n",
      "Epoch start: TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 10 - Loss: 9413.4395 - Accuracy: 0.1465\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 20 - Loss: 8845.2305 - Accuracy: 0.1667\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 30 - Loss: 9156.7969 - Accuracy: 0.1485\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 40 - Loss: 9535.2051 - Accuracy: 0.1438\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 50 - Loss: 9113.2422 - Accuracy: 0.1448\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 60 - Loss: 9853.6201 - Accuracy: 0.1403\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 70 - Loss: 9577.8047 - Accuracy: 0.1382\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 80 - Loss: 9287.6865 - Accuracy: 0.1465\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 90 - Loss: 9590.9619 - Accuracy: 0.1479\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 100 - Loss: 9516.6738 - Accuracy: 0.1429\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 110 - Loss: 9349.2070 - Accuracy: 0.1434\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 120 - Loss: 9542.6191 - Accuracy: 0.1437\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 130 - Loss: 8829.5488 - Accuracy: 0.1451\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 140 - Loss: 9226.4893 - Accuracy: 0.1427\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 150 - Loss: 9703.6416 - Accuracy: 0.1257\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 160 - Loss: 9233.2119 - Accuracy: 0.1380\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 170 - Loss: 9402.5137 - Accuracy: 0.1559\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 180 - Loss: 9270.2812 - Accuracy: 0.1477\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 190 - Loss: 9392.2666 - Accuracy: 0.1521\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 200 - Loss: 9548.8936 - Accuracy: 0.1438\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 210 - Loss: 9239.3496 - Accuracy: 0.1609\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "Batch 220 - Loss: 9111.1855 - Accuracy: 0.1739\n",
      "TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "\n",
      "Train Loss: 9343.2832 - Train Accuracy: 0.1468\n",
      "Valid Loss: 9296.7881 - Valid Accuracy: 0.1418\n",
      "Epoch end: TensorFlow reported memory: 187MB (Peak: 3585MB)\n",
      "\n",
      "End of training...\n",
      "Total duration: 0:17:34.022773\n",
      "\n",
      "Model Parameters Summary:\n",
      "Trainable params: 3,250,478\n",
      "Non-trainable params: 10\n",
      "Total params: 3,250,488\n"
     ]
    }
   ],
   "source": [
    "seq2seq_model, optimizer = create_model()\n",
    "train_model(seq2seq_model, train_loader, valid_loader, optimizer, loss_fn, epochs, teacher_forcing_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data...\n",
      "Test Loss: 8889.0928 - Test Accuracy: 0.1492\n"
     ]
    }
   ],
   "source": [
    "avg_loss, avg_accuracy = evaluate(seq2seq_model, test_loader, loss_fn)\n",
    "print(\"Evaluating on test data...\")\n",
    "print(f\"Test Loss: {avg_loss:.4f} - Test Accuracy: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top-1 accuracy буде низьким, якщо правильний клас не має найвищої ймовірності у багатьох випадках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, en_nlp, en_vocab, de_vocab, sos_token, eos_token, max_output_length=50):\n",
    "    model.trainable = False\n",
    "    id_to_token = {id: token for token, id in de_vocab.items()}\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        en_tokens = [token.text for token in en_nlp.tokenizer(sentence)]\n",
    "    else:\n",
    "        en_tokens = [token for token in sentence]\n",
    "    \n",
    "    en_tokens = [token.lower() for token in en_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    \n",
    "    en_ids = [en_vocab[token] if token in en_vocab else en_vocab[\"<unk>\"] for token in en_tokens]\n",
    "    \n",
    "    src = tf.expand_dims(en_ids, 0) \n",
    "    # src = [1, src_len]\n",
    "\n",
    "    decoder_input = tf.constant([[de_vocab[sos_token]]])\n",
    "\n",
    "    encoder_all_states, encoder_last_state = model.encoder(src, training=False)\n",
    "\n",
    "    decoder_current_hidden_state = encoder_last_state\n",
    "    \n",
    "    output_tokens = [sos_token]\n",
    "    \n",
    "    for _ in range(max_output_length):\n",
    "        step_output, decoder_current_hidden_state = model.decoder(\n",
    "            decoder_input,\n",
    "            decoder_current_hidden_state,\n",
    "            encoder_all_states,\n",
    "            training=False\n",
    "        )\n",
    "\n",
    "        predicted_id = int(tf.argmax(step_output, axis=-1))\n",
    "        \n",
    "        predicted_token = id_to_token[predicted_id]\n",
    "\n",
    "        output_tokens.append(predicted_token)\n",
    "        \n",
    "        if predicted_token == eos_token:\n",
    "            break\n",
    "\n",
    "        decoder_input = tf.constant([[predicted_id]])\n",
    "    \n",
    "    return en_tokens, output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <sos> a man in an orange hat starring at something . <eos>\n",
      "Output: <sos> ein mann mit einem orangefarbenen hut , der etwas anstarrt . <eos>\n",
      "Predictions: <sos> mann in einem einem einem einem <unk> . <eos>\n",
      "\n",
      "Input: <sos> a boston terrier is running on lush green grass in front of a white fence . <eos>\n",
      "Output: <sos> ein boston terrier läuft über saftig-grünes gras vor einem weißen zaun . <eos>\n",
      "Predictions: <sos> mann in einem einem einem , einem einem , . . . <eos>\n",
      "\n",
      "Input: <sos> a girl in karate uniform breaking a stick with a front kick . <eos>\n",
      "Output: <sos> ein mädchen in einem karateanzug bricht ein brett mit einem tritt . <eos>\n",
      "Predictions: <sos> mann in einem einem einem , einem einem , . . <eos>\n",
      "\n",
      "Input: <sos> five people wearing winter jackets and helmets stand in the snow , with snowmobiles in the background . <eos>\n",
      "Output: <sos> fünf leute in winterjacken und mit helmen stehen im schnee mit schneemobilen im hintergrund . <eos>\n",
      "Predictions: <sos> mann in einem einem und einem , einem , einem , einem <unk> . . <eos>\n",
      "\n",
      "Input: <sos> people are fixing the roof of a house . <eos>\n",
      "Output: <sos> leute reparieren das dach eines hauses . <eos>\n",
      "Predictions: <sos> mann in einem einem <unk> . <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (5):\n",
    "    en_tokens, output_tokens = translate_sentence(test_data[\"en\"][i], seq2seq_model, en_nlp, en_vocab, de_vocab, sos_token, eos_token)\n",
    "    print(\"Input: \" + \" \".join(en_tokens))\n",
    "    print(\"Output: \" + \" \".join(test_data[\"de_tokens\"][i]))\n",
    "    print(\"Predictions: \" + \" \".join(output_tokens) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
