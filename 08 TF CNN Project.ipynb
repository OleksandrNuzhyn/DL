{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data), ds_info = tfds.load('food101', split=['train', 'validation'], shuffle_files=True, as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features['label'].names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_data.take(1):\n",
    "    print(image.shape)\n",
    "    print(image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_data = test_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.take(1).get_single_element()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DTypePolicy \"mixed_float16\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(101)(x)\n",
    "outputs = tf.keras.layers.Activation(\"softmax\", dtype=tf.float32)(x)\n",
    "\n",
    "model1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_top = model1.fit(train_data, epochs=50, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0005), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_ft1 = model1.fit(train_data, epochs=100, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])\n",
    "\n",
    "for layer in base_model.layers[-60:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_ft2 = model1.fit(train_data, epochs=100, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(test_data, steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(101)(x)\n",
    "outputs = tf.keras.layers.Activation(\"softmax\", dtype=tf.float32)(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_top = model2.fit(train_data, epochs=50, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_ft1 = model2.fit(train_data, epochs=100, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])\n",
    "\n",
    "for layer in base_model.layers[-60:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0005), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_ft2 = model2.fit(train_data, epochs=100, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(test_data, steps=len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не перевищувати розмір batch_size = 32. Не вистачає пам'яті"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739013631.344089   29197 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1739013642.350684   29197 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 33ms/step - accuracy: 0.3831 - loss: 3.8301 - val_accuracy: 0.5850 - val_loss: 2.9062\n",
      "Epoch 2/50\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 24ms/step - accuracy: 0.4874 - loss: 3.1851 - val_accuracy: 0.5829 - val_loss: 2.8994\n",
      "Epoch 3/50\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 24ms/step - accuracy: 0.4909 - loss: 3.1730 - val_accuracy: 0.5861 - val_loss: 2.9030\n",
      "Epoch 4/50\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 24ms/step - accuracy: 0.4896 - loss: 3.1738 - val_accuracy: 0.5857 - val_loss: 2.9021\n",
      "Epoch 5/50\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 23ms/step - accuracy: 0.4866 - loss: 3.1850 - val_accuracy: 0.5823 - val_loss: 2.9054\n",
      "Epoch 6/50\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 23ms/step - accuracy: 0.4908 - loss: 3.1779 - val_accuracy: 0.5855 - val_loss: 2.9006\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 1/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 40ms/step - accuracy: 0.5359 - loss: 2.4811 - val_accuracy: 0.7296 - val_loss: 1.3695\n",
      "Epoch 2/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 27ms/step - accuracy: 0.6538 - loss: 1.6793 - val_accuracy: 0.7556 - val_loss: 1.2054\n",
      "Epoch 3/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 27ms/step - accuracy: 0.7027 - loss: 1.4499 - val_accuracy: 0.7747 - val_loss: 1.1176\n",
      "Epoch 4/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 27ms/step - accuracy: 0.7404 - loss: 1.2839 - val_accuracy: 0.7799 - val_loss: 1.0894\n",
      "Epoch 5/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 27ms/step - accuracy: 0.7660 - loss: 1.1665 - val_accuracy: 0.7831 - val_loss: 1.0758\n",
      "Epoch 6/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.7857 - loss: 1.0755 - val_accuracy: 0.7849 - val_loss: 1.0818\n",
      "Epoch 7/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 27ms/step - accuracy: 0.8074 - loss: 0.9791 - val_accuracy: 0.7890 - val_loss: 1.0686\n",
      "Epoch 8/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 27ms/step - accuracy: 0.8218 - loss: 0.9178 - val_accuracy: 0.7843 - val_loss: 1.0895\n",
      "Epoch 9/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 27ms/step - accuracy: 0.8345 - loss: 0.8606 - val_accuracy: 0.7863 - val_loss: 1.1040\n",
      "Epoch 10/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 27ms/step - accuracy: 0.8440 - loss: 0.8182 - val_accuracy: 0.7845 - val_loss: 1.1106\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 1/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 39ms/step - accuracy: 0.8140 - loss: 0.9320 - val_accuracy: 0.8044 - val_loss: 0.9403\n",
      "Epoch 2/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 29ms/step - accuracy: 0.8652 - loss: 0.7140 - val_accuracy: 0.8054 - val_loss: 0.9261\n",
      "Epoch 3/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 29ms/step - accuracy: 0.8843 - loss: 0.6402 - val_accuracy: 0.8053 - val_loss: 0.9184\n",
      "Epoch 4/100\n",
      "\u001b[1m 842/2368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:56\u001b[0m 312ms/step - accuracy: 0.8949 - loss: 0.5950"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(101, kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "outputs = tf.keras.layers.Activation(\"softmax\", dtype=tf.float32)(x)\n",
    "\n",
    "model3 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_top = model3.fit(train_data, epochs=50, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])\n",
    "\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0005), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_ft1 = model3.fit(train_data, epochs=100, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])\n",
    "\n",
    "for layer in base_model.layers[-60:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history_ft2 = model3.fit(train_data, epochs=100, validation_data=test_data, steps_per_epoch=len(train_data), validation_steps=len(test_data), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
